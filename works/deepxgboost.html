<!DOCTYPE html>
<html>

<head>
	<title>Jona</title>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1">
	
	<!-- style / responsive -->
	<link href="assets/css/bootstrap.min.css" rel="stylesheet" type="text/css" />
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
	<link rel="stylesheet" type="text/css" href="../css/style.css">

	<!-- fonts -->
	<link href='https://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'>
	<!-- icons -->
	<link href="../assets/fonts-icons/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
	<!-- for FF, Chrome, Opera -->
	<link rel="icon" type="image/png" href="" sizes="16x16">
	<link rel="icon" type="image/png" href="" sizes="32x32">

	<!-- for IE -->
	<link rel="icon" type="image/x-icon" href="" >
	<link rel="shortcut icon" type="image/x-icon" href=""/>

</head>
<body>

	<header class="wrapper site-header">
		<div class="row">
			<hgroup>
				<h1 class="site-title">
					<a href="../index.html"> Jona </a>
				</h1>
				<h2 class="site-description">
					Machine Learning Engineer
				</h2>
			</hgroup>
			<!-- Navigation Bar -->
			<nav class="navbar navbar-static-top center" role="navigation">
				<div class="navbar-header ">
					<button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-menubuilder">	
						<span class="sr-only">Toggle navigation</span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
					</button>
				</div>
				<div class="collapse navbar-collapse navbar-menubuilder navbar-inner">
					<ul class="nav navbar-nav">
						<li><a href="../index.html" class="page-scroll">Projects</a></li>
						<li><a href="../aboutme.html" class="page-scroll">About Me</a></li>
						<li><a href="../thesis.html" class="page-scroll">Thesis </a></li>
						<li><a href="../contact.html" class="page-scroll">Contact </a></li>
						<!--<li><a class="page-scroll" href="#"><b> BLOG </b></a></li>-->
					</ul>
				</div>
			</nav>
			<!-- /Navigation Bar -->
		</div>
	</header>

	<section class="middle wrapper">
		<div class="row">
			<div id="primary" class="site-content">
				<!-- #content -->
				<div id="content" role="main">
					<div class="blog-posts readable-content">
						<!-- .post -->
						<article class="post type-post hentry">
							<!-- .entry-header -->
							<header class="entry-header">
								<h1 class="entry-title">
									<a href="#" title="Permalink to Adaptive Vs. Responsive Layouts And Optimal Form Field Labels" rel="bookmark">CNNs and Gradient Boosting for Image Classification</a>
								</h1>
							</header>
							<!-- .entry-header -->
							 
							 <!-- .entry-meta --> 
							<footer class="entry-meta">
								<ul>
									<li><p href="#">TensorFlow</p></li>
									<li><p href="#">Keras</p></li>
									<li><p href="#">Computer Vision</p></li>
									<li><p href="#">XGBoost</p></li>
									<li>
										<p href="#">
											<a href="https://github.com/jonaac/deep-xgboost-image-classifier">
												<i class="fa fa-github"></i>
											</a>
										</p>
									</li>
								</ul>			
							</footer>

							<div class="featured-image">
								<img src="../img/deepxgboost.gif" alt="blog-image">
							</div>
							<!-- .entry-meta --> 
							
							<!-- .entry-content -->
							<div class="entry-content work">

								<p class="abstract"> I was first introduced to XGBoost when I was working as a data scientist. I was surprised at how accurate, efficient, and interpretable it was. Naturally, I was very intrigued by recent research [<a href="https://pubmed.ncbi.nlm.nih.gov/30713552/" target="_blank">1</a>, <a href="https://dl.acm.org/doi/10.1145/3123266.3127902" target="_blank">2</a>] suggesting a new CNN+XGBoost architecture for non-image classification tasks. It inspired me to look into its potential for real-world application, so I decided to further test this idea with more complex datasets and larger CNN structures. Results show that with a simple CNN architecture the CNN-XGBoost model outperforms the traditional CNN model. But, when working with more complex CNN structures the hybrid model is not as accurate as the original CNN architectures. <a href="https://github.com/jonaac/deep-xgboost-image-classifier" target="_blank" class="more-link">Github Reposiroty <span class="meta-nav"> â†’</span></a>
								</p>

								<h2 style="text-align: center">CNNs and Gradient Boosting for Image Classification</h2>

								<p class="article"> Image classification has been one of the fundamental problems in the field of image processing and can be considered the basis of other computer vision problems (image localization, segmentation, object detection, etc.). The introduction of deep learning and deep neural networks [<a href="https://www.deeplearningbook.org/" target="_blank">3</a>] has been essential to the advancement of computer vision and has produced continuous breakthroughs in image classification [<a href="http://www.cs.toronto.edu/~fritz/absps/ncfast.pdf" target="_blank">4</a>][<a href="https://research.aston.ac.uk/en/publications/a-study-on-cnn-transfer-learning-for-image-classification" target="_blank">5</a>].</p>

								<p class="article">Convolutional neural networks (CNN) are one of the most popular deep learning architectures for image classification. The popularity of CNNs come from their ability to process and extract features from images through their convolutional and pooling layers. Said features are then fed to a fully connected neural network that performs the classification task. Even though CNNs have been acknowledged as outstanding feature extractors, the traditional classification layers can fail to interpret the extracted features.</p>

								<div class="featured-image">
									<img src="../img/cnn_structure.png" alt="blog-image">
								</div>
								<footer class="entry-meta">
									Convolutional Neural Network architecture.
								</footer>https://arxiv.org/pdf/1603.02754.pdf

								<p class="article"> eXtreme Gradient Boosting [<a href="https://arxiv.org/pdf/1603.02754.pdf" target="_blank">6</a>] (XGBoost) is a machine learning algorithm built on the principles of the gradient tree boosting algorithm and designed for speed and performance. In recent years XBoost has become a very popular classifier due to its efficiency and accuracy. I wanted to examine if I could improve the performance of traditional CNNs by integrating CNNs with an XGBoost classifier. Our goal is to leverage the CNN to extract quality features and feed them as input to the XGBoost to classify images.

								<p class="article"> What exactly does the CNN-XGBoost model look like? The CNN maintains all of its feature extracting layers, and the feature flattening later. The XGBoost model replaces the fully connected NN and will perform the classification task based on the flattened features obtained from the CNN. How do I train the CNN-XGBoost model? First, I train the CNN with the original images. Then, I drop the fully connected layers and feed the flattened features (from the trained CNN) to an XGBoost model to train it for classification. The goal is for XGBoost to obtain quality features from the images and provide more accurate results than the traditional CNN architecture.</p>

								<div class="featured-image">
									<img src="../img/cnn_xgboost.gif" alt="blog-image">
								</div>
								<footer class="entry-meta">
									CNN-XGBoost architecture
								</footer>

								<p class="article">Previous work on the CNN-XGBoost model has either dealt only with singular dimension inputs [<a href="https://pubmed.ncbi.nlm.nih.gov/30713552/" target="_blank">1</a>, <a href="https://dl.acm.org/doi/10.1145/3123266.3127902" target="_blank">2</a>] or based on simple (in terms of structure) CNN architectures [<a href="https://link.springer.com/chapter/10.1007/978-3-319-64185-0_28" target="_blank">7</a>]. For this project, I  test the CNN-XGBoost model with the CIFAR-10 dataset, a set of labeled 32x32x3 colored images classified into ten categories. I evaluate the proposed model with three different CNN architectures, a baseline CNN, VGG16, and ResNet.</p>

								<p class="article">The baseline architecture is built to replicate the baseline performance porposed by the team that provides the CIFAR-10 dataset. It consists of six convolutional layers, with three max pooling layer, one every two convolutional layers, and a flattening layer. The VGG16 architecture was introduced by K. Simonyan and A. Zisserman [<a href="https://arxiv.org/pdf/1409.1556.pdf" target="_blank">8</a>] and was able to achieve a 92.7% top-5 accuracy for the ImageNet dataset (14 million images belonging to 1000 classes). The ResNet architecture has been one of the most groundbreaking neural network architectures in the field of computer vision. It was introduced by He et al. [<a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank">9</a>] in 2015. I will be using ResNet-50 which is 50 layers deep.</p>

								<div class="featured-image">
									<img src="../img/vgg16.png" alt="blog-image">
									<img src="../img/resnet50.png" alt="blog-image">
								</div>
								<footer class="entry-meta">
									VGG16 architechture and a sample of a ResNet architecture.
								</footer>

								<p class="article">After training all three variants of the CNN-XGBoost model, I evaluated their performance by comparing their accuracy with the original CNN and two other hybrid classifiers, CNN-SVM and CNN-kNN.</p>

								<div class="featured-image list">
									<ul>
										<li><img src="../img/baseline_acc.png" alt="blog-image"></li>
										<li><img src="../img/vgg16_acc.png" alt="blog-image"></li>
										<li><img src="../img/resnet_acc.png" alt="blog-image"></li>
									</ul>
								</div>
								<footer class="entry-meta">
									Accuracy of the Baseline, the VGG16 and the ReNet50 based models.
								</footer>

								<p class="article">In all three cases, the CNN-XGBoost model was able to outperform the CNN-SVM & CNN-kNN models. The more complex the CNN structure, the more prominent the difference was between our proposed model and the other two hybrid models. In the case of the baseline CNN, the CNN-XGBoost model was also able to outperform the original CNN. Once we started working with the more complex models, both VGG16-XGBoost and ResNet-XGBoost had lower accuracy than their original CNN models.  The more complex the architecture, the more significant the difference was in performance.</p>

								<p class="article">Due to a lack of resources, the parameters used for XGBoost were tuned manually. It could explain why the performance with VGG16 and ResNet-50 architectures (which had more complex classification layers) was not as accurate. This is something I would like to test better in the future. resources</p>

								<p class="References">

								</p>

							</div>
							<!-- .entry-content -->
						</article>
					</div>
						<!-- .blog-posts -->
				</div>
				<!-- #content --> 
			</div>
		</div>
	</section>

	<script type="text/javascript" src="../assets/js/bootstrap.min.js"></script>
	<script type="text/javascript" src="../assets/js/bootstrap.min.js"></script>
	<script type="text/javascript" src="../js/vendors/scrolloverflow.min.js"></script>

	<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
	<script type="text/javascript" src="../js/script.js"></script>
</body>

</html>
