<!DOCTYPE html>
<html>

<head>
	<title>Jona</title>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1">
	
	<!-- style / responsive -->
	<link href="assets/css/bootstrap.min.css" rel="stylesheet" type="text/css" />
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
	<link rel="stylesheet" type="text/css" href="css/style.css">

	<!-- fonts -->
	<link href='https://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'>
	<!-- icons -->
	<link href="assets/fonts-icons/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
	<!-- for FF, Chrome, Opera -->
	<link rel="icon" type="image/png" href="" sizes="16x16">
	<link rel="icon" type="image/png" href="" sizes="32x32">

	<!-- for IE -->
	<link rel="icon" type="image/x-icon" href="" >
	<link rel="shortcut icon" type="image/x-icon" href=""/>

</head>
<body>

	<header class="wrapper site-header">
		<div class="row">
			<hgroup>
				<h1 class="site-title">
					<a href="index.html"> Jona </a>
				</h1>
				<h2 class="site-description">
					Machine Learning Engineer
				</h2>
			</hgroup>
			<!-- Navigation Bar -->
			<nav class="navbar navbar-static-top center" role="navigation">
				<div class="navbar-header ">
					<button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-menubuilder">	
						<span class="sr-only">Toggle navigation</span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
					</button>
				</div>
				<div class="collapse navbar-collapse navbar-menubuilder navbar-inner">
					<ul class="nav navbar-nav">
						<li><a href="index.html">Projects</a></li>
						<li><a href="aboutme.html">About Me</a></li>
						<li><a href="thesis.html" class="selected">Thesis</a></li>
						<li><a href="contact.html">Contact</a></li>
						<!--<li><a class="page-scroll" href="#"><b> BLOG </b></a></li>-->
					</ul>
				</div>
			</nav>
			<!-- /Navigation Bar -->
		</div>
	</header>

	<section class="middle wrapper">
		<div class="row">
			<div id="primary" class="site-content">
				<!-- #content -->
			<div id="primary" class="site-content">
				<!-- #content -->
				<div id="content" role="main">
					<div class="blog-posts readable-content">
						<!-- .post -->
						<article class="post type-post hentry">
							<!-- .entry-header -->
							<header class="entry-header">
								<h1 class="entry-title">
									<a href="#" title="Permalink to Adaptive Vs. Responsive Layouts And Optimal Form Field Labels" rel="bookmark">Reward Specification in Constrained Markov Decision Processes</a>
								</h1>
							</header>
							<!-- .entry-header -->
							 
							 <!-- .entry-meta --> 
							<footer class="entry-meta">
								<ul>
									<li><p href="#">TensorFlow</p></li>
									<li><p href="#">Keras</p></li>
									<li><p href="#">LTL</p></li>
									<li><p href="#">OpenAI</p></li>
									<li>
										<p href="#">
											<a href="files/ThesisProposal.pdf" target="_blank">
												<i class="fa fa-file-o"></i>
											</a>
										</p>
									</li>
								</ul>			
							</footer>

							<div class="featured-image">
								<img src="img/openai.gif" alt="blog-image">
							</div>
							<!-- .entry-meta --> 
							
							<!-- .entry-content -->
							<div class="entry-content work">

								<p class="abstract"> I am currently working on my thesis for my master's. I am under the supervisio	n of Professor Yves Lesperance and Professor Ruth Urner at York University. If you want further details please feel free to check my full thesis proposal.<a href="files/ThesisProposal.pdf" target="_blank" class="more-link">Thesis Proposal<span class="meta-nav"> →</span></a> </p>

								<header class="entry-header">
									<h1 class="entry-title">Abstract</h1>
								</header>
								
								<p class="article"> This thesis will focus on improving two of the main concerns with reinforcement learning, safety and performance. When training an agent in a MDP the main focus is to maximize the cumulative reward it receives. So, the exploration process typically does not concern itself with potential threats to the agent and therefore can not guarantee its safety. Constrained Markov Decision Processes (CMDPs) are a special form of MDPs that allow for the separation of safety specification from the reward function by naturally encoding the safety concerns as constraints. In a CMDP the goal is to learn an optimal policy that maximizes the cumulative reward and whose cumulative cost is under the established upper bound.
								</p>

								<div class="featured-image" style="max-width: 350px;">
									<img src="img/cddpg.png" alt="blog-image">
								</div>
								<footer class="entry-meta">
									The optimization problem to solve for a CMDP.
								</footer>

								<p class="article">In addition, intelligent agents do not have access to the reward function governing their environment. For the agents, the reward function is a black box that will return an immediate reward given their current state. One way to approach this limitation is by introducing the use of logic to supply prior knowledge to the agent. Icarte et al. [2018a] introduced Reward Machines (RM), a special form of finite state machine that would allow the agent to be exposed to the structure of the reward function.
								</p>

								<div class="featured-image">
									<img src="img/rm.png" alt="blog-image">
								</div>
								<footer class="entry-meta">
									A Reward Machine describing the agent (purple) its task. Pick up the coffee (c) and bring it to the office (o) without hitting any vases (*).
								</footer>

								<p class="article">
								I am proposing the integration of Reward Machines, into Constrained Markov Decision Processes. The goal is to develop a safer and more efficient solution to the constrained RL control problem. The idea is to use Linear Temporal Logic (LTL) to translate the reward functions into formal rewards and use it to construct an equivalent Reward Machine. I will be using the RM to transform the CMDP into a new framework called CMDP with a Reward Machine (CMDPRM) and, to solve the CMDPRM I will be developing a new algorithm called Constrained Learning for RM (CLRM) that will leverage the RM to achieve a faster and safer learning process. The goal is to test and evaluate the proposed methodology in the Safety Gym benchmark suite developed by Ray et al. [2019], which consists of high-dimensional continuous control environments meant to measure the performance and safety of agents in Constrained Markov Decision Processes.
								</p>

								<div class="featured-image">
									<img src="img/safety-gym.png" alt="blog-image">
								</div>
								<footer class="entry-meta">
									Examples of benchmark environments from the Safety Gym library.
								</footer>

								<a href="files/ThesisProposal.pdf" target="_blank" class="more-link">Thesis Proposal<span class="meta-nav"> →</span></a> </p>

							</div>
							<!-- .entry-content -->
						</article>
					</div>
						<!-- .blog-posts -->
				</div>
				<!-- #content --> 
			</div>
				<!-- #content --> 
			</div>
		</div>
	</section>

	<script type="text/javascript" src="assets/js/bootstrap.min.js"></script>
	<script type="text/javascript" src="assets/js/bootstrap.min.js"></script>
	<script type="text/javascript" src="js/vendors/scrolloverflow.min.js"></script>

	<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
	<script type="text/javascript" src="js/script.js"></script>
</body>

</html>
